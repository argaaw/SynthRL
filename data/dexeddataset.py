"""
Implementation of the DexedDataset, based on the PresetBased abstract class.

Wav files, spectrograms statistics, etc., can be re-generated by running this script as main.
See end of file.
"""
import os
import psutil
from typing import Optional, Iterable
import multiprocessing
from tqdm import tqdm
from omegaconf import OmegaConf
from datetime import datetime
from scipy.signal import resample
from typing import List, Tuple
from pyvirtualdisplay import Display
import torch
import soundfile
import numpy as np

from synth import dexed
from utils.audio import suppress_output
from data import abstractbasedataset
from data.preset import DexedPresetsParams, PresetIndexesHelper


class DexedDataset(abstractbasedataset.PresetDataset):
    def __init__(
        self,
        note_duration: List[float],
        n_fft: int,
        fft_hop: int,
        n_mel_bins: int = 128,
        midi_notes: Tuple[Tuple[int, int]] = ((60, 85),),
        normalize_audio: bool = False,
        algos: Optional[List[int]] = None,
        operators: Optional[List[int]] = None,
        vst_params_learned_as_categorical: Optional[str] = None,
        constant_filter_and_tune_params: bool = True,
        dataset_dir: Optional[str] = None,
        num_param_bins: int = 25,
        sample_rate: int = 22050,
        **kwargs,
    ):
        """
        Allows access to Dexed preset values and names, and generates spectrograms and corresponding
        parameters values. Can manage a reduced number of synth parameters (using default values for non-
        learnable params). Only Dexed-specific ctor args are described - see base PresetDataset class.

        It uses both the SQLite DB (through dexed.PresetDatabase) and the pre-written files extracted from
        the DB (see dexed.PresetDatabase.write_all_presets_to_files(...)).

        :param algos: List. Can be used to limit the DX7 algorithms included in this dataset. Set to None
            to use all available algorithms
        :param operators: List of ints, or None. Enables the specified operators only, or all of them if None.
        :param vst_params_learned_as_categorical: 'all_num' to learn all vst params as numerical, 'vst_cat'
            to learn vst cat params as categorical, or 'all<=x' to learn all vst params (including numerical) with
            cardinality <= xxx (e.g. 8 or 32) as categorical
        :param constant_filter_and_tune_params: if True, the main filter and the main tune settings are default
        """
        super().__init__(
            note_duration,
            n_fft,
            fft_hop,
            n_mel_bins,
            midi_notes,
            normalize_audio,
            dataset_dir,
            sample_rate
        )
        self.constant_filter_and_tune_params = constant_filter_and_tune_params
        self.algos = algos if algos is not None else []
        self._operators = operators if operators is not None else [1, 2, 3, 4, 5, 6]

        # Full SQLite DB read and temp storage in np arrays
        dexed_db = dexed.PresetDatabase()
        self._total_nb_presets = dexed_db.presets_mat.shape[0]
        self._total_nb_params = dexed_db.presets_mat.shape[1]
        self._param_names = dexed_db.get_param_names()

        # Constraints on parameters, learnable VST parameters
        self.learnable_params_idx = list(range(0, dexed_db.presets_mat.shape[1]))
        
        if self.constant_filter_and_tune_params:  # (see dexed_db_explore.ipynb)
            for vst_idx in [0, 1, 2, 3, 13]:
                self.learnable_params_idx.remove(vst_idx)
        
        for i_op in range(6):  # Search for disabled operators
            if (i_op + 1) not in self._operators:  # If disabled: we remove all corresponding learnable params
                for vst_idx in range(21):  # Don't remove the 22nd param (OP on/off selector) yet
                    self.learnable_params_idx.remove(23 + 22 * i_op + vst_idx)  # idx 23 is the first param of op 1
        
        # Oscillators can be enabled or disabled, but OP SWITCHES are never learnable parameters
        for col in [44, 66, 88, 110, 132, 154]:
            self.learnable_params_idx.remove(col)

        # Valid presets - UIDs of presets, and not their database row index
        # Select valid presets by algorithm
        if len(self.algos) == 0:  # All presets are valid
            self.valid_preset_UIDs = dexed_db.all_presets_df["index_preset"].values
        else:
            if len(self.algos) == 1:
                self.learnable_params_idx.remove(4)  # Algo parameter column idx
            valid_presets_row_indexes = dexed_db.get_preset_indexes_for_algorithms(self.algos)
            self.valid_preset_UIDs = dexed_db.all_presets_df.iloc[valid_presets_row_indexes]['index_preset'].values
        
        # DB class deleted (we need a low memory usage for multi-process dataloaders)
        del dexed_db
        
        # Parameters constraints, cardinality, indexes management, ...
        # Param cardinalities are stored - Dexed cardinality involves a short search which can be avoided
        # This cardinality is the LEARNING REPRESENTATION cardinality - will be used for categorical representations
        self._params_cardinality = np.asarray([dexed.Dexed.get_param_cardinality(idx, num_param_bins)
                                               for idx in range(self.total_nb_params)])
        self._params_default_values = dict()

        # Algo cardinality is manually set. We consider an algo-limited DX7 to be a new synth
        if len(self.algos) > 0:  # len 0 means all algorithms are used
            self._params_cardinality[4] = len(self.algos)
        if len(self.algos) == 1:  # 1 algo: constrained constant param
            self._params_default_values[4] = (self.algos[0] - 1) / 31.0

        # cardinality 1 for constrained parameters (operators are always constrained)
        self._params_cardinality[[44, 66, 88, 110, 132, 154]] = np.ones((6,), dtype=np.int16)
       
        for op_i, op_switch_idx in enumerate([44, 66, 88, 110, 132, 154]):
            self._params_default_values[op_switch_idx] = 1.0 if ((op_i + 1) in self._operators) else 0.0
       
        if self.constant_filter_and_tune_params:
            self._params_cardinality[[0, 1, 2, 3, 13]] = np.ones((5,), dtype=np.int16)
            self._params_default_values[0] = 1.0
            self._params_default_values[1] = 0.0
            self._params_default_values[2] = 1.0
            self._params_default_values[3] = 0.5
            self._params_default_values[13] = 0.5

        # None / Numerical / Categorical learnable status array
        self._vst_param_learnable_model = list()
        num_vst_learned_as_cat_cardinal_threshold = None
        
        if vst_params_learned_as_categorical is not None:
            if vst_params_learned_as_categorical.startswith('all<='):
                num_vst_learned_as_cat_cardinal_threshold = int(vst_params_learned_as_categorical.replace('all<=', ''))
            else:
                assert vst_params_learned_as_categorical == 'vst_cat'

        # We go through all VST params indexes
        for vst_idx in range(self.total_nb_params):
            if vst_idx not in self.learnable_params_idx:
                self._vst_param_learnable_model.append(None)
            else:
                if vst_params_learned_as_categorical is None:  # Default: forced numerical only
                    self._vst_param_learnable_model.append('num')
                else:  # Mixed representations: is the VST param numerical?
                    if vst_idx in dexed.Dexed.get_numerical_params_indexes():
                        if num_vst_learned_as_cat_cardinal_threshold is None:  # If no threshold: learned as numerical
                            self._vst_param_learnable_model.append('num')
                        # If a non-continuous param has a small enough cardinality: might be learned as categorical
                        elif 1 < self._params_cardinality[vst_idx] <= num_vst_learned_as_cat_cardinal_threshold:
                            self._vst_param_learnable_model.append('cat')
                        else:
                            self._vst_param_learnable_model.append('num')
                    # If categorical VST param: must be learned as cat (at this point)
                    elif vst_idx in dexed.Dexed.get_categorical_params_indexes():
                        self._vst_param_learnable_model.append('cat')
                    else:
                        raise ValueError("VST param idx={} is neither numerical nor categorical".format(vst_idx))
        # Final initializations
        self._preset_idx_helper = PresetIndexesHelper(self)
        self._load_preset_params()

    @property
    def synth_name(self):
        return "Dexed"

    def __str__(self):
        return "{}. Enabled algorithms: {}. Enabled operators: {}"\
            .format(super().__str__(),
                    ('all' if len(self.algos) == 0 else self.algos), self._operators)

    @property
    def total_nb_presets(self):
        return self._total_nb_presets

    @property
    def vst_param_learnable_model(self):
        return self._vst_param_learnable_model

    @property
    def numerical_vst_params(self):
        return dexed.Dexed.get_numerical_params_indexes()

    @property
    def categorical_vst_params(self):
        return dexed.Dexed.get_categorical_params_indexes()

    @property
    def params_default_values(self):
        return self._params_default_values

    @property
    def total_nb_params(self):
        return self._total_nb_params

    @property
    def preset_indexes_helper(self):
        return self._preset_idx_helper

    @property
    def preset_param_names(self):
        return self._param_names

    def get_preset_param_cardinality(self, idx, learnable_representation=True):
        if idx == 4 and learnable_representation is False:
            return 32
        return self._params_cardinality[idx]

    def get_full_preset_params(self, preset_UID):
        raw_full_preset = dexed.PresetDatabase.get_preset_params_values_from_file(preset_UID)
        return DexedPresetsParams(full_presets=torch.unsqueeze(torch.tensor(raw_full_preset, dtype=torch.float32), 0),
                                  dataset=self)

    def _render_audio(self, preset_params: Iterable, midi_note, midi_velocity):
        # reload the VST to prevent hanging notes/sounds
        dexed_renderer = dexed.Dexed(
            midi_note_duration_s=self.note_duration[0],
            render_duration_s=self.note_duration[0] + self.note_duration[1],
            sample_rate=self.sample_rate
        )
        dexed_renderer.assign_preset(dexed.PresetDatabase.get_params_in_plugin_format(preset_params))
        x_wav = dexed_renderer.render_note(midi_note, midi_velocity, normalize=self.normalize_audio)
        return x_wav, dexed_renderer.Fs

    @property
    def _operators_suffix(self):
        """ Returns a suffix (to be used in files names) that describes enabled DX7 operators, as configured
        in this dataset's constructor. Return an empty string if all operators are used. """
        ops_suffix = ''
        if self._operators != [1, 2, 3, 4, 5, 6]:
            ops_suffix = '_op' + ''.join(['{}'.format(op) for op in self._operators])
        return ops_suffix

    def _load_preset_params(self):
        try:
            self.preset_params = torch.load(self.params_path)
        except IOError:
            print(f'[PresetDataset] Cannot open params.pt file.')
    
    def generate_preset_params(self):
        total_num = len(self.valid_preset_UIDs)
        preset_params = torch.zeros((total_num, self.preset_indexes_helper._learnable_preset_size))

        for i, preset_UID in tqdm(enumerate(self.valid_preset_UIDs), total=total_num):
            single_preset = self.get_full_preset_params(preset_UID).get_learnable()
            preset_params[i] = single_preset.squeeze()

        torch.save(preset_params, self.params_path)
        print(f'Preset parameters tensor of {preset_params.shape} has been saved')
        return preset_params
    
    def get_data_from_file(self, preset_UID, midi_pitch, midi_velocity):
        waveform = self.get_wav_file(preset_UID, midi_pitch, midi_velocity)
        spectrogram = self.get_spec_file(preset_UID, midi_pitch, midi_velocity)
        return waveform, spectrogram
    
    def get_spec_file_path(self, preset_UID, midi_note, midi_velocity):
        """ Returns the path of a spectrogram (from dexed_presets folder). Operators"""
        filename = "preset{:06d}_midi{:03d}vel{:03d}{}.pt".format(preset_UID, midi_note, midi_velocity,
                                                                   self._operators_suffix)
        return self.spec_files_dir.joinpath(filename)

    def get_spec_file(self, preset_UID, midi_note, midi_velocity):
        file_path = self.get_spec_file_path(preset_UID, midi_note, midi_velocity)
        try:
            spectrogram = torch.load(file_path)
            return spectrogram.unsqueeze(0)
        except RuntimeError:
            raise RuntimeError("[data/dataset.py] Can't open file {}. Please pre-render spectrogram files for this "
                               "dataset configuration.".format(file_path))

    def get_wav_file_path(self, preset_UID, midi_note, midi_velocity):
        """ Returns the path of a wav (from dexed_presets folder). Operators"""
        filename = "preset{:06d}_midi{:03d}vel{:03d}{}.wav".format(int(preset_UID), midi_note, midi_velocity,
                                                                   self._operators_suffix)
        return self.wav_files_dir.joinpath(filename)

    def get_wav_file(self, preset_UID, midi_note, midi_velocity):
        file_path = self.get_wav_file_path(preset_UID, midi_note, midi_velocity)
        try:
            waveform = soundfile.read(file_path)[0].astype(np.float32)
            return waveform
        except RuntimeError:
            raise RuntimeError("[data/dataset.py] Can't open file {}. Please pre-render audio files for this "
                               "dataset configuration.".format(file_path))

    def generate_wav_files(self, write_sr):
        """ Reads all presets (names, param values, and labels) from .pickle and .txt files
         (see dexed.PresetDatabase.write_all_presets_to_files(...)) and renders them
         using attributes and constraints of this class (midi note, normalization, etc...)

         Floating-point .wav files will be stored in dexed presets' folder (see synth/dexed.py)
         """
        t_start = datetime.now()
        os.makedirs(self.wav_files_dir, exist_ok=True)
        num_workers = int(np.round(os.cpu_count() * 0.2))
        workers_args = self._get_multi_note_workers_args(num_workers)
        self.write_sr = write_sr

        # Multi-process rendering
        with multiprocessing.Pool(num_workers) as p:
            p.map(self._generate_wav_files_batch, workers_args)

        delta_t = (datetime.now() - t_start).total_seconds()
        num_wav_written = len(self.valid_preset_UIDs) * len(self.midi_notes)
        print("Finished writing {} .wav files ({:.1f}s total, {:.1f}ms/file)"
              .format(num_wav_written, delta_t, 1000.0*delta_t/num_wav_written))

    def _generate_wav_files_batch(self, worker_args):
        """
        Generates wav files using the given list of (preset_UID, midi_pitch, midi_vel) tuples.
        """
        pid = os.getpid()
        cpus = list(range(psutil.cpu_count()))
        os.sched_setaffinity(pid, cpus)
        worker_idx = worker_args[0][1]
        
        for args in tqdm(worker_args, position=worker_idx, leave=True, total=len(worker_args)):
            preset_UID, midi_pitch, midi_vel = args[0]
            self._generate_single_wav_file(preset_UID, midi_pitch, midi_vel)

    def _generate_single_wav_file(self, preset_UID, midi_pitch, midi_velocity):
        preset_params = self.get_full_preset_params(preset_UID)

        with suppress_output():
            x_wav, Fs = self._render_audio(
                torch.squeeze(preset_params.get_full(apply_constraints=True), 0),
                midi_pitch,
                midi_velocity
            )

        num_samples = int(len(x_wav) * self.write_sr / Fs)
        resampled_wav = resample(x_wav, num_samples)
        soundfile.write(self.get_wav_file_path(preset_UID, midi_pitch, midi_velocity),
                        resampled_wav, self.write_sr, subtype='FLOAT')


if __name__ == "__main__":
    dataset_config = OmegaConf.load('config/dataset/dexed.yaml')
    # ============== DATA RE-GENERATION ==================
    write_sr = 22050
    regenerate_wav = True
    regenerate_spectrograms_stats = True
    regenerate_preset_params = True

    # xvfb display activation via pyvirtualdisplay wrapper
    disp = Display().start()

    dexed_dataset = DexedDataset(
        normalize_audio=True,
        **dataset_config,
    )

    if regenerate_wav:
        print(f'\nGenerating wav files...')
        dexed_dataset.generate_wav_files(write_sr=write_sr)
    
    if regenerate_spectrograms_stats:
        print(f'\nGenerating spectrogram files...')
        dexed_dataset.generate_melspec_files()

    if regenerate_preset_params:
        print(f'\nGenerating preset params...')
        print(len(dexed_dataset))
        preset_params = dexed_dataset.generate_preset_params()

    # xvfb display deactivation
    disp.stop()
