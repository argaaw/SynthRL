# SynthRL: Cross-domain Synthesizer Sound Matching via Reinforcement Learning

This repository contains the source code developed for our IJCAI 2025 paper.

## Requirements

To set up the environment, install the required dependencies:
```
pip install -r requirements.txt
```

- **Dexed synthesizer**: The model training and dataset generation require the Dexed synthesizer. Please refer to the Dexed repository https://github.com/asb2m10/dexed and RenderMan repository https://github.com/fedden/RenderMan for installation instructions on a Linux system.
- **Surge synthesizer**: The out-of-domain dataset generation requires the Surge synthesizer. Please refer to the Surge repository https://github.com/surge-synthesizer/surge for installation instructions.

## Dataset
### In-domain (Dexed dataset)
Due to size limitations, the dataset is not included in this repository. It can be generated by running:
```
python -m data.dexeddataset
```

### Out-of-domain (Surge XT-derived)
[Download](https://github.com/argaaw/SynthRL/releases/download/v1.0.0/surge.tar.gz)
- The dataset was rendered using **Surge XT** with publicly available presets collected from the internet.
- Includes only rendered audio clips and spectrograms; no preset files are included.
- Individual presets are subject to their authors’ original terms. We **do not** redistribute any preset files here.

**Takedown / contact**
- If you are a rightsholder and request removal or attribution changes, contact: `<swc0406@snu.ac.kr>`. We will promptly review and update or remove the relevant items.

## Model Checkpoints
- Dexed (in-domain): [Download](https://github.com/argaaw/SynthRL/releases/download/v1.0.0/in-domain-dexed.tar)
- Surge (out-of-domain): [Download](https://github.com/argaaw/SynthRL/releases/download/v1.0.0/out-of-domain-surge.tar)

Checksums are listed in the release notes.

## Usage
### Train
SynthRL training process consists of three stages, as described in our paper:

1. **Stage 1**: Run `train.py` to train the model using only parameter loss.
```
python train.py
```
2. **Stage 2**: Run `finetune.py` with the `dexed` dataset.
```
python finetune.py --config-name stage2
```
3. **Stage 3**: Run `finetune.py` with the `surge` dataset.
```
python finetune.py --config-name stage3
```

### Evaluation
To evaluate the trained model, execute:
```
python evaluate.py
```

## Citation
If you use this work, please cite our paper:
```
@inproceedings{shin2025synthrl,
  title   = {{SynthRL}: Cross-domain Synthesizer Sound Matching via Reinforcement Learning},
  author  = {Shin, Wonchul and Lee, Kyogu},
  year    = {2025},
  booktitle   = {Proceedings of the 34th International Joint Conference on Artificial Intelligence}
}
```
We also acknowledge the upstream work (DAFx 2021):
```
@inproceedings{levaillant2021vaesynthprog,
	title        = {Improving Synthesizer Programming from Variational Autoencoders Latent Space},
	author       = {Le Vaillant, Gwendal and Dutoit, Thierry and Dekeyser, Sébastien},
	year         = 2021,
	month        = Sep,
	booktitle    = {Proceedings of the 24th International Conference on Digital Audio Effects (DAFx20in21)},
	location     = {Vienna, Austria}
}
```

## Attribution & License

This repository includes portions of code originally from Preset-Gen-VAE (https://github.com/gwendal-lv/preset-gen-vae).
Because it contains AGPL-3.0–licensed portions, this repository is distributed under **AGPL-3.0**.  
See `LICENSE` and `NOTICE`.
